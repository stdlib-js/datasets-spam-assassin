{"id":"01755","group":"easy-ham-1","checksum":{"type":"MD5","value":"51e8b76626231abf27c682904ee4b4c1"},"text":"Return-Path: anthony@interlink.com.au\nDelivery-Date: Thu Sep 12 01:23:51 2002\nFrom: anthony@interlink.com.au (Anthony Baxter)\nDate: Thu, 12 Sep 2002 10:23:51 +1000\nSubject: [Spambayes] Current histograms \nIn-Reply-To: <LNBBLJKPBEHFEDALKOLCKEJBBDAB.tim.one@comcast.net> \nMessage-ID: <200209120023.g8C0NpQ18478@localhost.localdomain>\n\n\n\n> How were these msgs broken up into the 5 sets?  Set4 in particular is giving\n> the other sets severe problems, and Set5 blows the f-n rate on everything\n> it's predicting -- when the rates across runs within a training set vary by\n> as much as a factor of 25, it suggests there was systematic bias in the way\n> the sets were chosen.  For example, perhaps they were broken into sets by\n> arrival time.  If that's what you did, you should go back and break them\n> into sets randomly instead.  If you did partition them randomly, the wild\n> variance across runs is mondo mysterious.\n\nThey weren't partitioned in any particular scheme - I think I'll write a\nreshuffler and move them all around, just in case (fwiw, I'm using MH \nstyle folders with numbered files - means you can just use MH tools to \nmanipulate the sets.)\n\n\n> For whatever reason, there appear to be few of those in BruceG's spam\n> collection.  I added code to strip uuencoded sections, and pump out uuencode\n> summary tokens instead.  I'll check it in.  It didn't make a significant\n> difference on my usual test run (a single spam in my Set4 is now judged as\n> ham by the other 4 sets; nothing else changed).  It does shrink the database\n> size here by a few percent.  Let us know whether it helps you!\n\nI'll give it a go.\n\n\n-- \nAnthony Baxter     <anthony@interlink.com.au>   \nIt's never too late to have a happy childhood.\n\n"}