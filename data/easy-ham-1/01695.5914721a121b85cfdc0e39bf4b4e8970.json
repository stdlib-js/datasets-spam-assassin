{"id":"01695","group":"easy-ham-1","checksum":{"type":"MD5","value":"5914721a121b85cfdc0e39bf4b4e8970"},"text":"Return-Path: guido@python.org\nDelivery-Date: Sat Sep  7 06:33:23 2002\nFrom: guido@python.org (Guido van Rossum)\nDate: Sat, 07 Sep 2002 01:33:23 -0400\nSubject: [Spambayes] Ditching WordInfo\nIn-Reply-To: Your message of \"Fri, 06 Sep 2002 22:17:28 PDT.\"\n             <w53n0qubcpj.fsf@woozle.org> \nReferences: <LNBBLJKPBEHFEDALKOLCOEKKBCAB.tim.one@comcast.net>  \n            <w53n0qubcpj.fsf@woozle.org> \nMessage-ID: <200209070533.g875XN813509@pcp02138704pcs.reston01.va.comcast.net>\n\n> Yeah, that's exactly what I was doing--I didn't realize I was\n> incurring administrative pickle bloat this way.  I'm specifically\n> trying to make things faster and smaller, so I'm storing individual\n> WordInfo pickles into an anydbm dict (keyed by token).  The result\n> is that it's almost 50 times faster to score messages one per run\n> our of procmail (.408s vs 18.851s).\n\nThis is very worthwhile.\n\n> However, it *does* say all over the place that the goal of this\n> project isn't to make the fastest or the smallest implementation, so\n> I guess I'll hold off doing any further performance tuning until the\n> goal starts to point more in that direction.  .4 seconds is probably\n> fast enough for people to use it in their procmailrc, which is what\n> I was after.\n\nMaybe.  I batch messages using fetchmail (don't ask why), and adding\n.4 seconds per message for a batch of 50 (not untypical) feels like a\nreal wait to me...\n\n--Guido van Rossum (home page: http://www.python.org/~guido/)\n"}