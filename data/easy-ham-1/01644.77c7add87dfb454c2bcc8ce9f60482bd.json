{"id":"01644","group":"easy-ham-1","checksum":{"type":"MD5","value":"77c7add87dfb454c2bcc8ce9f60482bd"},"text":"Return-Path: tim.one@comcast.net\nDelivery-Date: Fri Sep  6 15:45:27 2002\nFrom: tim.one@comcast.net (Tim Peters)\nDate: Fri, 06 Sep 2002 10:45:27 -0400\nSubject: [Spambayes] test sets?\nIn-Reply-To: <15736.5577.157228.229200@12-248-11-90.client.attbi.com>\nMessage-ID: <LNBBLJKPBEHFEDALKOLCGEHCBCAB.tim.one@comcast.net>\n\n[Tim]\n> OTOH, my Data/ subtree currently has more than 35,000 files slobbering\n> over 134 million bytes -- even if I had a place to put that much stuff,\n> I'm not sure my ISP would let me email it in one msg <wink>.\n\n[Skip]\n> Do you have a dialup or something more modern <wink>?\n\nMuch more modern:  a cable modem with a small upload rate cap.  There's a\nreason the less modern uncapped @Home went out of business <wink>.\n\n> 134MB of messages zipped would probably compress pretty well - under 50MB\n> I'd guess with all the similarity in the headers and such.  You could zip\n> each of the 10 sets individually and upload them somewhere.\n\nI suppose this could finish over the course of an afternoon.  Now where's\n\"somewhere\"?  I expect we'll eventually collect several datasets;\nSourceForge isn't a good place for it (they expect projects to distribute\nrelatively small code files, and complain if even those get big).\n\n> ...\n> How about random sampling lots of public mailing lists via gmane or\n> something similar, manually cleaning it (distributing that load over a\n> number of people) and then relying on your clever code and your\n> rebalancing script to help further cleanse it?\n\nWhat then are we training the classifier to do?  Graham's scoring scheme is\nbased on an assumption that the ham-vs-spam task is *easy*, and half of that\nis due to that the ham has a lot in common.  It was an experiment to apply\nhis scheme to all the comp.lang.python traffic, which is a lot broader than\nhe had in mind (c.l.py has long had a generous definition of \"on topic\"\n<wink>).  I don't expect good things to come of making it ever broader,\n*unless* your goal is to investigate just how broad it can be made before it\nbreaks down.\n\n> The \"problem\" with the ham is it tends to be much more tied to one person\n> (not just intimate, but unique) than the spam.\n\nWhich is \"a feature\" from Graham's POV:  the more clues, the better this\n\"smoking guns only\" approach should work.\n\n> I save all incoming email for ten days (gzipped mbox format) before it\nrolls\n> over and disappears.  At any one time I think I have about 8,000-10,000\n> messages.  Most of it isn't terribly personal (which I would cull before\n> passing along anyway) and much of it is machine-generated, so would be of\n> marginal use.  Finally, it's all ham-n-spam mixed together.  Do we call\n> that an omelette or a Denny's Grand Slam?\n\nUnless you're volunteering to clean it, tag it, package it, and distribute\nit, I'd call it irrelevant <wink>.\n\n"}