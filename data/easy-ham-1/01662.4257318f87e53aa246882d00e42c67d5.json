{"id":"01662","group":"easy-ham-1","checksum":{"type":"MD5","value":"4257318f87e53aa246882d00e42c67d5"},"text":"Return-Path: tim.one@comcast.net\nDelivery-Date: Fri Sep  6 18:35:55 2002\nFrom: tim.one@comcast.net (Tim Peters)\nDate: Fri, 06 Sep 2002 13:35:55 -0400\nSubject: [Spambayes] Deployment\nIn-Reply-To: <15736.55193.38098.486459@slothrop.zope.com>\nMessage-ID: <LNBBLJKPBEHFEDALKOLCKEIHBCAB.tim.one@comcast.net>\n\n[Jeremy Hylton]\n> I think one step towards deployment is creating a re-usable tokenizer\n> for mail messages.  The current codebase doesn't expose an easy-to-use\n> or easy-to-customize tokenizer.\n\ntokenize() couldn't be easier to use:  it takes a string argument, and\nproduces a stream of tokens (whether via explicit list, or generator, or\ntuple, or ... doesn't matter).  All the tokenize() functions in GBayes.py\nand timtest.py are freely interchangeable this way.\n\nNote that we have no evidence to support that a customizable tokenizer would\ndo any good, or, if it would, in which ways customization could be helpful.\nThat's a research issue on which no work has been done.\n\n> The timtest module seems to contain an enormous body of practical\n> knowledge about how to parse mail messages, but the module wasn't\n> designed for re-use.\n\nThat's partly a failure of imagination <wink>.  Splitting out all knowledge\nof tokenization is just a large block cut-and-paste ... there, it's done.\nChange the\n\n    from timtoken import tokenize\n\nat the top to use any other tokenizer now.  If you want to make it easier\nstill, feel free to check in something better.\n\n> I'd like to see a module that can take a single message or a collection of\n> messages and tokenize each one.\n\nThe Msg and MsgStream classes in timtest.py are a start at that, but it's\nhard to do anything truly *useful* here when people use all sorts of\ndifferent physical representations for email msgs (mboxes in various\nformats, one file per \"folder\", one file per msg, Skip's gzipped gimmick,\n...).  If you're a Python coder <wink>, you *should* find it very easy to\nchange the guts of Msg and MsgStream to handle your peculiar scheme.\nDefining interfaces for these guys should be done.\n\n> I'd like to see the tokenize by customizable, too.  Tim had to exclude\n> some headers from his test data, because there were particular biases\n> in the test data.  If other people have test data without those\n> biases, they ought to be able to customize the tokenizer to include\n> them or exclude others.\n\nThis sounds like a bottomless pit to me, and there's no easier way to\ncustomize than to edit the code.  As README.txt still says, though, massive\nrefactoring would help.  Hop to it!\n\n"}