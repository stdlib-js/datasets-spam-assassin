{"id":"01749","group":"easy-ham-1","checksum":{"type":"MD5","value":"da79f6e9c4f07174e5dec173c9481b99"},"text":"Return-Path: tim.one@comcast.net\nDelivery-Date: Tue Sep 10 20:01:36 2002\nFrom: tim.one@comcast.net (Tim Peters)\nDate: Tue, 10 Sep 2002 15:01:36 -0400\nSubject: [Spambayes] Current histograms\nIn-Reply-To: <200209100929.g8A9TJV27347@localhost.localdomain>\nMessage-ID: <BIEJKCLHCIOIHAGOKOLHEEHMDKAA.tim.one@comcast.net>\n\n[Anthony Baxter]\n> Well, I've finally got around to pulling down the SF code. Starting\n> with it, and absolutely zero local modifications, I see the following:\n\nHow many runs is this summarizing?  For each, how many ham&spam were in the\ntraining set?  How many in the prediction sets?  What were the error rates\n(run rates.py over your output file)?\n\nThe effect of set sizes on accuracy rates isn't known.  I've informally\nreported some results from just a few controlled experiments on that.\nJeremy reported improved accuracy by doubling the training set size, but\nthat wasn't a controlled experiment (things besides just training set size\nchanged between \"before\" and \"after\").\n\n> Ham distribution for all runs:\n> * = 589 items\n>   0.00 35292 ************************************************************\n>   2.50    36 *\n>   5.00    21 *\n>   7.50    12 *\n>  10.00     6 *\n> ...\n>  90.00     4 *\n>  92.50     8 *\n>  95.00    15 *\n>  97.50   441 *\n>\n> Spam distribution for all runs:\n> * = 504 items\n>   0.00   393 *\n>   2.50    17 *\n>   5.00    18 *\n>   7.50    12 *\n>  10.00     4 *\n> ...\n>  90.00    11 *\n>  92.50    16 *\n>  95.00    45 *\n>  97.50 30226 ************************************************************\n>\n>\n> My next (current) task is to complete the corpus I've got - it's currently\n> got ~ 9000 ham, 7800 spam, and about 9200 currently unsorted. I'm tossing\n> up using either hammie or spamassassin to do the initial sort  -\npreviously\n> I've used various forms of 'grep' for keywords and a little gui thing to\n> pop a message up and let me say 'spam/ham', but that's just getting too,\ntoo\n> tedious.\n\nYup, tagging data is mondo tedious, and mistakes hurt.\n\nI expect hammie will do a much better job on this already than hand\ngrepping.  Be sure to stare at the false positives and get the spam out of\nthere.\n\n> I can't make it available en masse, but I will look at finding some of\n> the more 'interesting' uglies. One thing I've seen (consider this\n> 'anecdotal' for now) is that the 'skip' tokens end up in a _lot_ of the\n> f-ps.\n\nWith probabilities favoring ham or spam?  A skip token is produced in lieu\nof \"word\" more than 12 chars long and without any high-bit characters.  It's\npossible that they helped me because raw HTML produces lots of these.\nHowever, if you're running current CVS, Tokenizer/retain_pure_html_tags\ndefaults to False now, so HTML decorations should vanish before body\ntokenization.\n\n"}