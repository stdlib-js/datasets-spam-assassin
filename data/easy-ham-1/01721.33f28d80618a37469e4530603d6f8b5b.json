{"id":"01721","group":"easy-ham-1","checksum":{"type":"MD5","value":"33f28d80618a37469e4530603d6f8b5b"},"text":"Return-Path: tim.one@comcast.net\nDelivery-Date: Sun Sep  8 21:01:00 2002\nFrom: tim.one@comcast.net (Tim Peters)\nDate: Sun, 08 Sep 2002 16:01:00 -0400\nSubject: [Spambayes] test sets?\nIn-Reply-To: <LNBBLJKPBEHFEDALKOLCEEOGBCAB.tim.one@comcast.net>\nMessage-ID: <LNBBLJKPBEHFEDALKOLCCEPLBCAB.tim.one@comcast.net>\n\n[Tim]\n> One effect of getting rid of MINCOUNT is that it latches on more\n> strongly to rare clues now, and those can be unique to the corpus\n> trained on (e.g., one trained ham says \"gryndlplyx!\", and a followup\n> new ham quotes it).\n\nThis may be a systematic bias in the testing procedure:  in real life, msgs\ncome ordered in time.  Say there's a thread that spans N messages on c.l.py.\nIn our testing setup, we'll train on a random sampling throughout its whole\nlifetime, and test likewise.  New ham \"in the middle\" of this thread gets\nbenefit from that we trained on msgs that appeared both before and *after*\nit in real life.  It's quite plausible that the f-p rate would rise without\nthis effect; in real life, at any given time some number of ham threads will\njust be starting their lives, and if they're at all unusual the trained data\nwill know little to nothing about them.\n\n"}