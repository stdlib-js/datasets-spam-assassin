{"id":"01704","group":"easy-ham-1","checksum":{"type":"MD5","value":"7f2b82a41322fa94c43a0dbb75472ff4"},"text":"Return-Path: jeremy@alum.mit.edu\nDelivery-Date: Sat Sep  7 18:18:17 2002\nFrom: jeremy@alum.mit.edu (Jeremy Hylton)\nDate: Sat, 7 Sep 2002 13:18:17 -0400\nSubject: [Spambayes] understanding high false negative rate\nIn-Reply-To: <LNBBLJKPBEHFEDALKOLCCEKNBCAB.tim.one@comcast.net>\nReferences: <15737.16782.542869.368986@slothrop.zope.com>\n\t<LNBBLJKPBEHFEDALKOLCCEKNBCAB.tim.one@comcast.net>\nMessage-ID: <15738.13529.407748.635725@slothrop.zope.com>\n\n>>>>> \"TP\" == Tim Peters <tim.one@comcast.net> writes:\n\n  TP> [Jeremy Hylton[\n  >> The total collections are 1100 messages.  I trained with 1100/5\n  >> messages.\n\n  TP> I'm reading this now as that you trained on about 220 spam and\n  TP> about 220 ham.  That's less than 10% of the sizes of the\n  TP> training sets I've been using.  Please try an experiment: train\n  TP> on 550 of each, and test once against the other 550 of each.\n\nThis helps a lot!  Here are results with the stock tokenizer:\n\nTraining on <mbox: /home/jeremy/Mail/INBOX 0> & <mbox: /home/jeremy/Mail/spam 8>\n ... 644 hams & 557 spams\n      0.000  10.413\n      1.398   6.104\n      1.398   5.027\nTraining on <mbox: /home/jeremy/Mail/INBOX 0> & <mbox: /home/jeremy/Mail/spam 0>\n ... 644 hams & 557 spams\n      0.000   8.259\n      1.242   2.873\n      1.242   5.745\nTraining on <mbox: /home/jeremy/Mail/INBOX 2> & <mbox: /home/jeremy/Mail/spam 3>\n ... 644 hams & 557 spams\n      1.398   5.206\n      1.398   4.488\n      0.000   9.336\nTraining on <mbox: /home/jeremy/Mail/INBOX 2> & <mbox: /home/jeremy/Mail/spam 0>\n ... 644 hams & 557 spams\n      1.553   5.206\n      1.553   5.027\n      0.000   9.874\ntotal false pos 139 5.39596273292\ntotal false neg 970 43.5368043088\n\nAnd results from the tokenizer that looks at all headers except Date,\nReceived, and X-From_:\n\nTraining on <mbox: /home/jeremy/Mail/INBOX 0> & <mbox: /home/jeremy/Mail/spam 8>\n ... 644 hams & 557 spams\n      0.000   7.540\n      0.932   4.847\n      0.932   3.232\nTraining on <mbox: /home/jeremy/Mail/INBOX 0> & <mbox: /home/jeremy/Mail/spam 0>\n ... 644 hams & 557 spams\n      0.000   7.181\n      0.621   2.873\n      0.621   4.847\nTraining on <mbox: /home/jeremy/Mail/INBOX 2> & <mbox: /home/jeremy/Mail/spam 3>\n ... 644 hams & 557 spams\n      1.087   4.129\n      1.087   3.052\n      0.000   6.822\nTraining on <mbox: /home/jeremy/Mail/INBOX 2> & <mbox: /home/jeremy/Mail/spam 0>\n ... 644 hams & 557 spams\n      0.776   3.411\n      0.776   3.411\n      0.000   6.463\ntotal false pos 97 3.76552795031\ntotal false neg 738 33.1238779174\n\nIs it safe to conclude that avoiding any cleverness with headers is a\ngood thing?\n\n  TP> Do that a few times making a random split each time (it won't be\n  TP> long until you discover why directories of individual files are\n  TP> a lot easier to work -- e.g., random.shuffle() makes this kind\n  TP> of thing trivial for me).\n\nYou haven't looked at mboxtest.py, have you?  I'm using\nrandom.shuffle(), too.  You don't need to have many files to make an\narbitrary selection of messages from an mbox.\n\nI'll report some more results when they're done.\n\nJeremy\n\n\n"}